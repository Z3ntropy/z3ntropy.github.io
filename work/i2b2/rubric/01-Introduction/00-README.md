## Introduction

Thank you for agreeing to participate in this confirmatory review of the i2b2 AI Cell architecture document. Your expert feedback is crucial to ensure that the AI Cell is designed to meet the real-world needs of the i2b2 community.

The **i2b2 AI Cell** is a new component designed to augment the i2b2 platform with AI-powered services. We are taking a **staged development approach**, and this review focuses on establishing a solid baseline understanding of how researchers are currently using i2b2 *without* AI assistance. This baseline will be crucial for evaluating the impact and effectiveness of the AI Cell in the future.

## Purpose of This Review:

This review seeks to validate our understanding of current i2b2 usage patterns *before* we incorporate the specifics of AI-related functionalities. We are requesting your feedback on:

* **Use Case Scenarios:** 
	* Do the provided scenarios accurately reflect the typical range of i2b2 usage you observe at your institution?
* **Proficiency Levels:** 
	* Are the defined proficiency levels (Novice, Beginner, Intermediate, Advanced, Expert) appropriate and comprehensive?
* **Rubric:** 
	* Is the rubric clear, relevant, and effective in assessing i2b2 proficiency across different dimensions?

---

**Important Note:** This review focuses on the *current state* of i2b2 usage *without* the AI Cell. We are interested in understanding how users currently interact with the platform and assess their proficiency. We will incorporate AI-related aspects in a follow-up to this documentation set.

---
## Review Materials

Documents in **this confirmatory set** include the following:

├── 01-Introduction/
│   ├── README: This file
│   └── [MVP Query Proficiency Rubric](01-MVP-Query-Proficiency-Rubric.md): An overview of the rubric.
│   └── [Use Case Summary](/01-Introduction/03-Summary-of-Use-Case-Scenarios.md): Table summarizing the (8) use case scenarios.
│   └── [Use Case Scenarios](02-Use-Case-Scenarios.md): Full use case descriptions including workflow diagrams.

---
## Feedback Questions

Please review the provided materials and provide feedback on the following:

1. **Use Case Scenarios:**
    * Do these scenarios accurately reflect the typical range of i2b2 usage you observe at your institution?
    * Are there any important use cases or scenarios that are missing or underrepresented?
    * Do the scenarios adequately capture the challenges faced by users at different proficiency levels?

2. **Proficiency Levels:**
    * Do the proficiency levels (Novice, Beginner, Intermediate, Advanced, Expert) adequately capture the different levels of i2b2 expertise you have observed in users?
    * Are the descriptions for each proficiency level clear and understandable?

3. **Rubric:**
    * Does the overall framework of the rubric make sense for assessing i2b2 query proficiency?
    * Are the dimensions (i2b2 Platform Proficiency, Domain Expertise, Query Complexity, Data Integration & External Resources, Security, Privacy, and Ethics, Collaboration) appropriate and comprehensive?
    * Are the descriptions for each proficiency level within each dimension clear and understandable? (A simplified rubric is provided for overview. Refer to the Appendix of the main architecture document for the full rubric).
    * Do you have any suggestions for improving the rubric's structure, content, or clarity?

4. **Collaboration Dimension:**
    * Do you agree with the inclusion of the "Collaboration" dimension and its focus on both external collaboration and personal query management?
    * Are the sub-dimensions within "Collaboration" appropriate and comprehensive?

5. **General:**
    * Is the documentation clear, concise, and easy to understand?
    * Do you have any other suggestions or feedback on the proposed framework?

Please submit your feedback by February 2nd to **Chris Connor** at [chris@relinvent.com](mailto:chris@relinvent.com).**

Thank you for your valuable input!
